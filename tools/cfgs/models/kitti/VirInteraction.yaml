CLASS_NAMES: ['Car','Pedestrian', 'Cyclist']  # prediction class

DATA_CONFIG:
    _BASE_CONFIG_: cfgs/dataset_configs/kitti_dataset.yaml
    DATASET: 'KittiDatasetSemi'
    INPUT_DISCARD_RATE: 0.8   # actually discard more than 90% virtual points of RGB image,
                              # as we only saved less than 50% RGB points during depth2points conversion.
    MM_PATH: 'velodyne_depth'
    ROT_NUM: 3
    USE_VAN: True

    DATA_SPLIT: {
        'train': trainsemi,  # train data, use:semi dataset
        'test': val  # val data
    }

    INFO_PATH: {
        'train': [kitti_infos_trainsemi.pkl],  # pkl
        'test': [kitti_infos_val.pkl],
    }
    SWAP: True
    DATA_AUGMENTOR:  # Augmentation
        DISABLE_AUG_LIST: ['placeholder']
        AUG_CONFIG_LIST:
            - NAME: gt_sampling
              AUG_WITH_IMAGE: True # use PC-Image Aug
              JOINT_SAMPLE: True # joint sample with point
              KEEP_RAW: False # keep original PC
              POINT_REFINE: True # refine points with different calib
              BOX_IOU_THRES: 0.5
              IMG_AUG_TYPE: by_depth  
              AUG_USE_TYPE: annotation 
              IMG_ROOT_PATH: semi/image_2

              USE_ROAD_PLANE: False
              DB_INFO_PATH:
                  - kitti_dbinfos_trainsemi.pkl
              PREPARE: {
                  filter_by_min_points: ['Car:5', 'Pedestrian:5', 'Cyclist:5'],
                  filter_by_difficulty: [-1],
              }

              SAMPLE_GROUPS: ['Car:0', 'Pedestrian:0', 'Cyclist:0']
              NUM_POINT_FEATURES: 8
              DATABASE_WITH_FAKELIDAR: False  
              REMOVE_EXTRA_WIDTH: [0.0, 0.0, 0]
              LIMIT_WHOLE_SCENE: False

            - NAME: random_world_rotation
              WORLD_ROT_ANGLE: [-0.78539816, 0.78539816]

            - NAME: random_world_flip
              ALONG_AXIS_LIST: ['x']

            - NAME: random_world_scaling
              WORLD_SCALE_RANGE: [0.95, 1.05]

    X_TRANS:  # Augmentation for TED
      AUG_CONFIG_LIST:
        - NAME: world_rotation
          WORLD_ROT_ANGLE: [0.3, 0.3, 0]
        - NAME: world_flip
          ALONG_AXIS_LIST: [0, 1., 1.]
        - NAME: world_scaling
          WORLD_SCALE_RANGE: [ 0.98, 1.02, 1.]


    POINT_FEATURE_ENCODING: {  # pos
        encoding_type: absolute_coordinates_encoding_mm,
        used_feature_list: ['x', 'y', 'z', 'intensity'],
        src_feature_list: ['x', 'y', 'z', 'intensity'],
        num_features: 8
    }

    DATA_PROCESSOR:
        - NAME: mask_points_and_boxes_outside_range
          REMOVE_OUTSIDE_BOXES: True

        - NAME: shuffle_points
          SHUFFLE_ENABLED: {
            'train': True,
            'test': False
          }

        - NAME: transform_points_to_voxels
          VOXEL_SIZE: [0.05, 0.05, 0.05]
          MAX_POINTS_PER_VOXEL: 5
          MAX_NUMBER_OF_VOXELS: {
            'train': 17000, # each modality only uses 16000 voxels during training
            'test': 40000
          }

MODEL:
    NAME: VoxelRCNN  # Detector

    VFE:
        NAME: MeanVFE
        MODEL: 'max'

    BACKBONE_3D:
        NAME: VirConv_segmKDE8x  # backbone name
        NUM_FILTERS: [16, 32, 64, 64]  # conv channels
        RETURN_NUM_FEATURES_AS_DICT: True
        OUT_FEATURES: 64
        MM: True  # Use virtual points
        # se-sampling
        USE_SEGM: True
        USE_SE_SAMPLING: [ 'vir_conv1' ]  # choose the stage of using se-sampling:
                                               # 'train', 'eval','vir_conv0','vir_conv1','vir_conv2','vir_conv3'WW
        SE_SAMPLING_ATTENTION: { 'self': 'linear','pos': 'sum' }  # choose the method of attention: 'self','cross','self+cross'
                                                      # choose the pos embedding method: 'linear', 'density'
        SE_SAMPLING_RATE: 0.8  # sampling ratio in se-sampling
        SAMPLING_FROM_OTHER_SCENES: False  # concatenate voxels from different batch to perform se-sampling
        # fgvd
        DISCARD_STAGE: { 'conv0': 'fgvd','conv1': 'fgvd','conv2': 'stvd','conv3': 'stvd' }
                                            # choose the stage of discarding the voxels:'conv0','conv1','conv2','conv3'
                                            # choose the method of discarding the voxels:'fgvd', 'stvd','kde','fgvd-kde'
        LAYER_DISCARD_RATE: 0.15  # discard ratio in conv3, conv4
        FORE_DISCARD_RATE: 0.1  # foreground threshold in FgVD
        BACK_DISCARD_RATE: 0.3  # background threshold in FgVD
        # img-voxel fusion
        MULTI_MODAL_FUSION: 'features'  # 'features' :fuse segmentation CNN features. 'rgb': fuse rgb features,or 'none'
        IMG_FUSION_TYPE: 'cross'  # choose the type of fusing the img and voxels: 'cat' or 'replace','cross',
                             # 'self+cross_transformer', 'cross_transformer' ,'self+cross_attention','multiscale_cross'

        IMG_POS_EMBEDDING: { 'density': 'sum', 'learning': 'shared_conv', 'proj':'shared_conv'}  # { 'linear': cat }
        TRANSFORMER_DEPTH: 2
        FUSION_STAGE: 'conv1'  #  choose the stage of fusing the img and voxels: 'conv0' ,'conv1' or 'none'
        ADD_CHANNELS: 64  # the additional channel in fusion of segmentation CNN features and voxel features
        SAVE_IMG_OUT_RANGE: True  # save the out-of-range voxels in FOV
        # density
        USE_DENSITY: False  # use KDE to estimate the density of voxels
        DENSITY_FUSION_TYPE: 'cat'  #  choose the type of fusing the density and voxels: 'cat','replace','multiply','sum'
        DENSITY_LEARNING: 'none'  # how to deal with the density: 'densitynet','mlp','conv','none','attention'
        DENSITY_POS_EMBEDDING: 'sum'
        RATE_LEARNING: 'mlp'  # select the mode of KDE denoising ratio
        # eval
        EVAL_WITH_NO_FUSION: True  #
    MAP_TO_BEV:
        NAME: HeightCompression
        NUM_BEV_FEATURES: 256

    BACKBONE_2D:
        NAME: BaseBEVBackbone

        LAYER_NUMS: [4, 4]
        LAYER_STRIDES: [1, 2]
        NUM_FILTERS: [64, 128]
        UPSAMPLE_STRIDES: [1, 2]
        NUM_UPSAMPLE_FILTERS: [128, 128]

    DENSE_HEAD:
        NAME: AnchorHeadSingle
        CLASS_AGNOSTIC: False

        USE_DIRECTION_CLASSIFIER: True
        DIR_OFFSET: 0.78539
        DIR_LIMIT_OFFSET: 0.0
        NUM_DIR_BINS: 2

        ANCHOR_GENERATOR_CONFIG: [  # prediction anchor generation
            {
                'class_name': 'Car',
                'anchor_sizes': [[3.9, 1.6, 1.56]],
                'anchor_rotations': [0, 1.57],
                'anchor_bottom_heights': [-1.78],
                'align_center': False,
                'feature_map_stride': 8,
                'matched_threshold': 0.6,
                'unmatched_threshold': 0.45
            },
            {
                'class_name': 'Pedestrian',
                'anchor_sizes': [[0.8, 0.6, 1.73]],
                'anchor_rotations': [0, 1.57],
                'anchor_bottom_heights': [-0.6],
                'align_center': False,
                'feature_map_stride': 8,
                'matched_threshold': 0.5,
                'unmatched_threshold': 0.35
            },
            {
                'class_name': 'Cyclist',
                'anchor_sizes': [[1.76, 0.6, 1.73]],
                'anchor_rotations': [0, 1.57],
                'anchor_bottom_heights': [-0.6],
                'align_center': False,
                'feature_map_stride': 8,
                'matched_threshold': 0.5,
                'unmatched_threshold': 0.35
            }
        ]
        TARGET_ASSIGNER_CONFIG:
            NAME: AxisAlignedTargetAssigner
            POS_FRACTION: -1.0
            SAMPLE_SIZE: 512
            NORM_BY_NUM_EXAMPLES: False
            MATCH_HEIGHT: False
            BOX_CODER: ResidualCoder

        LOSS_CONFIG:
            LOSS_WEIGHTS: {
                'cls_weight': 1.0,
                'loc_weight': 2.0,
                'dir_weight': 0.2,
                'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
            }


    ROI_HEAD:
        NAME: TEDMHead
        CLASS_AGNOSTIC: True
        ROT_NUM: 3
        USE_ATTENTION: 'self_transformer_encoder'  # use cross-attention to fuse img CNN feat and BEV feat
        TRANSFORMER_DEPTH: 2
        DENSITY_POS_EMBEDDING: { 'density': 'sum'}
        PART:
          IN_CHANNEL: 256
          SIZE: 7
          GRID_OFFSETS: [0., 40.]
          FEATMAP_STRIDE: 0.4

        SHARED_FC: [256, 256]
        CLS_FC: [256, 256]
        REG_FC: [256, 256]
        DP_RATIO: 0.01

        NMS_CONFIG:
            TRAIN:
                NMS_TYPE: nms_gpu
                MULTI_CLASSES_NMS: False
                NMS_PRE_MAXSIZE: 4000
                NMS_POST_MAXSIZE: 512
                NMS_THRESH: 0.8
            TEST:
                NMS_TYPE: nms_gpu
                MULTI_CLASSES_NMS: False
                USE_FAST_NMS: True
                SCORE_THRESH: 0.0
                NMS_PRE_MAXSIZE: 2000
                NMS_POST_MAXSIZE: 50
                NMS_THRESH: 0.75

        ROI_GRID_POOL:
            FEATURES_SOURCE: ['x_conv3','x_conv4']
            PRE_MLP: True
            GRID_SIZE: 6
            POOL_LAYERS:
                x_conv3:
                    MLPS: [[32, 32], [32, 32]]
                    QUERY_RANGES: [[2, 2, 2], [4, 4, 4]]
                    POOL_RADIUS: [0.4, 0.8]
                    NSAMPLE: [16, 16]
                    POOL_METHOD: max_pool
                x_conv4:
                    MLPS: [[32, 32], [32, 32]]
                    QUERY_RANGES: [[2, 2, 2], [4, 4, 4]]
                    POOL_RADIUS: [0.8, 1.6]
                    NSAMPLE: [16, 16]
                    POOL_METHOD: max_pool

        ROI_GRID_POOL_MM:
            FEATURES_SOURCE: ['x_conv3','x_conv4']
            PRE_MLP: True
            GRID_SIZE: 4
            POOL_LAYERS:
                x_conv3:
                    MLPS: [[32, 32], [32, 32]]
                    QUERY_RANGES: [[2, 2, 2], [4, 4, 4]]
                    POOL_RADIUS: [0.4, 0.8]
                    NSAMPLE: [16, 16]
                    POOL_METHOD: max_pool
                x_conv4:
                    MLPS: [[32, 32], [32, 32]]
                    QUERY_RANGES: [[2, 2, 2], [4, 4, 4]]
                    POOL_RADIUS: [0.8, 1.6]
                    NSAMPLE: [16, 16]
                    POOL_METHOD: max_pool

# For three class
        TARGET_CONFIG:
            BOX_CODER: ResidualCoder
            STAGE0:
                ROI_PER_IMAGE: 160
                FG_RATIO: 0.5
                SAMPLE_ROI_BY_EACH_CLASS: True
                CLS_SCORE_TYPE: roi_iou_x
                CLS_FG_THRESH: [ 0.75, 0.65, 0.65 ]
                CLS_BG_THRESH: [ 0.25, 0.15, 0.15 ]
                CLS_BG_THRESH_LO: 0.1
                HARD_BG_RATIO: 0.8
                REG_FG_THRESH: [ 0.5, 0.45, 0.45 ]
            STAGE1:
                ROI_PER_IMAGE: 160
                FG_RATIO: 0.5
                SAMPLE_ROI_BY_EACH_CLASS: True
                CLS_SCORE_TYPE: roi_iou_x
                CLS_FG_THRESH: [ 0.75, 0.65, 0.65 ]
                CLS_BG_THRESH: [ 0.25, 0.15, 0.15 ]
                CLS_BG_THRESH_LO: 0.1
                HARD_BG_RATIO: 0.8
                REG_FG_THRESH: [ 0.55, 0.5, 0.5 ]
            STAGE2:
                ROI_PER_IMAGE: 160
                FG_RATIO: 0.5
                SAMPLE_ROI_BY_EACH_CLASS: True
                CLS_SCORE_TYPE: roi_iou_x
                CLS_FG_THRESH: [ 0.75, 0.65, 0.65 ]
                CLS_BG_THRESH: [ 0.25, 0.15, 0.15 ]
                CLS_BG_THRESH_LO: 0.1
                HARD_BG_RATIO: 0.8
                REG_FG_THRESH: [ 0.6, 0.55, 0.55 ]

        LOSS_CONFIG:
            CLS_LOSS: BinaryCrossEntropy
            REG_LOSS: smooth-l1
            CORNER_LOSS_REGULARIZATION: True
            GRID_3D_IOU_LOSS: False
            LOSS_WEIGHTS: {
                'rcnn_cls_weight': 1.0,
                'rcnn_reg_weight': 1.0,
                'rcnn_corner_weight': 1.0,
                'rcnn_iou3d_weight': 1.0,
                'code_weights': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
            }

    POST_PROCESSING:
        RECALL_THRESH_LIST: [0.3, 0.5, 0.7]
        SCORE_THRESH: 0.4
        OUTPUT_RAW_SCORE: False
        EVAL_METRIC: kitti

        NMS_CONFIG:
            MULTI_CLASSES_NMS: False
            NMS_TYPE: nms_gpu
            NMS_THRESH: 0.1
            NMS_PRE_MAXSIZE: 4096
            NMS_POST_MAXSIZE: 500


OPTIMIZATION:
    BATCH_SIZE_PER_GPU: 1  # batch_size
    NUM_EPOCHS: 5

    OPTIMIZER: adam_onecycle
    LR: 0.01
    WEIGHT_DECAY: 0.01
    MOMENTUM: 0.9

    MOMS: [0.95, 0.85]
    PCT_START: 0.4
    DIV_FACTOR: 10
    DECAY_STEP_LIST: [35, 45]
    LR_DECAY: 0.1
    LR_CLIP: 0.0000001

    LR_WARMUP: False
    WARMUP_EPOCH: 1

    GRAD_NORM_CLIP: 10
